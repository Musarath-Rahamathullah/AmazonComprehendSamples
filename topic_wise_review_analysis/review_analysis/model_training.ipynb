{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a266ef",
   "metadata": {},
   "source": [
    "# Getting insight from customer reviews using Amazon Comprehend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ac667",
   "metadata": {},
   "source": [
    "## Comprehend Model Training Notebook\n",
    "In the previous Notebook we performed data cleaning, exploration, and analysis. Now in this Notebook we will run a Topic Modeling job in Amazon Comprehend to get - \n",
    "\n",
    "\n",
    "1. List of words associated with each topic with high probability\n",
    "2. Assignment of each document to topics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde059b8",
   "metadata": {},
   "source": [
    "## Initialize\n",
    "<a id=\"InitialiazeS3Data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f42e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json, time, tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60fcf2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Client and session information\n",
    "session = boto3.Session()\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Account id. Required downstream.\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "# Initializing Comprehend client\n",
    "comprehend = boto3.client(service_name='comprehend', \n",
    "                          region_name=session.region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315cbe1d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e17c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of topics set to 5 after having a human-in-the-loop\n",
    "# This needs to be fully aligned with topicMaps dictionary in the third script \n",
    "NUMBER_OF_TOPICS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd6e94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Input file format of one review per line\n",
    "input_doc_format = \"ONE_DOC_PER_LINE\"\n",
    "\n",
    "# Role arn (Hard coded- Hide)\n",
    "data_access_role_arn = \"arn:aws:iam::682523027102:role/service-role/AmazonSageMaker-ExecutionRole-20220525T154953\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da53f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for S3 bucket and input data file\n",
    "BUCKET = 'clothing-shoe-jewel-tm-blog'\n",
    "input_s3_url = f's3://{BUCKET}/out/TransformedReviews.txt'\n",
    "output_s3_url = f's3://{BUCKET}/out/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db0a13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_CONFIG={\n",
    "    # The S3 URI where training output is placed.\n",
    "    'S3Uri':    input_s3_url,\n",
    "    # Document format\n",
    "    'InputFormat': input_doc_format,\n",
    "}\n",
    "OUTPUT_CONFIG={\n",
    "    # The S3 URI where training output is placed.\n",
    "    'S3Uri':    output_s3_url,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08a3f0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Comprehend input file just to double check if number of reviews \n",
    "# and the number of lines in the input file have an exact match.\n",
    "obj = s3.Object(BUCKET, 'out/TransformedReviews.txt')\n",
    "comprehend_input = obj.get()['Body'].read().decode('utf-8')\n",
    "comprehend_input_lines = len(comprehend_input.split('\\n'))\n",
    "\n",
    "# Reviews where Comprehend outputs will be merged\n",
    "df = pd.read_csv(f's3://{BUCKET}/out/FinalDataframe.csv')\n",
    "review_df_length = df.shape[0]\n",
    "\n",
    "# The two lengths must be equal\n",
    "assert comprehend_input_lines == review_df_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7e2f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54afcb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts an asynchronous topic detection job\n",
    "def train_topics_detection(NumberOfTopics, InputConfig, OutputConfig, DataRoleArn):\n",
    "    # You can specify number of topics and Input and output config and IAM Role ARN \n",
    "    # that grants Amazon Comprehend read access to your input data. . \n",
    "    # Created The Amazon Resource Name (ARN), Job ID and Status of the topics detection job. \n",
    "\n",
    "    # Training takes a while to complete. \n",
    "    # You can track the current status by calling Use the DescribeTopicDetectionJob operation.\n",
    "    response = comprehend.start_topics_detection_job(NumberOfTopics=NumberOfTopics,\n",
    "                                                    InputDataConfig=InputConfig,\n",
    "                                                    OutputDataConfig=OutputConfig,\n",
    "                                                    DataAccessRoleArn=data_access_role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359af63e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Comprehend \n",
    "start_topics_detection_job_result = train_topics_detection( NUMBER_OF_TOPICS, \n",
    "                                                            INPUT_CONFIG, \n",
    "                                                            OUTPUT_CONFIG, \n",
    "                                                            data_access_role_arn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895fdb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start_topics_detection_job_result: ' + json.dumps(start_topics_detection_job_result))\n",
    "\n",
    "# Job ID is required downstream for extracting the Comprehend results\n",
    "job_id = start_topics_detection_job_result[\"JobId\"]\n",
    "print('job_id: ', job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84b88d0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check Training Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping track if Comprehend has finished its job\n",
    "description = comprehend.describe_topics_detection_job(JobId=job_id)\n",
    "\n",
    "TrainingJobStatus = description['TopicsDetectionJobProperties'][\"JobStatus\"]\n",
    "print(TrainingJobStatus)\n",
    "while TrainingJobStatus != \"COMPLETED\" and TrainingJobStatus != \"FAILED\":\n",
    "    time.sleep(120)\n",
    "    TrainingJobStatus = comprehend.describe_topics_detection_job(JobId=job_id)['TopicsDetectionJobProperties'][\"JobStatus\"]\n",
    "    print(TrainingJobStatus)\n",
    "\n",
    "TrainingJobStatus = comprehend.describe_topics_detection_job(JobId=job_id)['TopicsDetectionJobProperties'][\"JobStatus\"]\n",
    "print(TrainingJobStatus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428a6a2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22bd92b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Bucket prefix where model artifacts are stored\n",
    "prefix = f'out/output/{account_id}-TOPICS-{job_id}'\n",
    "\n",
    "# Location on S3 where model artifacts are stored\n",
    "target = f's3://{BUCKET}/{prefix}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66783c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List S3 files/folders where Comprehend saved its results as tar.gz\n",
    "! aws s3 ls {target} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the output file from artifacts\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(BUCKET)\n",
    "comprehend_out_file = ''\n",
    "# Loop through artifacts. The output files are zipped files.\n",
    "for my_bucket_object in my_bucket.objects.filter(Prefix=prefix):\n",
    "    if my_bucket_object.key.endswith('tar.gz'):\n",
    "        comprehend_out_file = 's3://' + BUCKET + '/' + my_bucket_object.key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31935eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Copy Comprehend output from S3 to local notebook instance\n",
    "! aws s3 cp {comprehend_out_file} ./comprehend-out/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae6f4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Unzip the Comprehend output file. \n",
    "# Two files are now saved locally- \n",
    "#       (1) comprehend-out/doc-topics.csv and \n",
    "#       (2) comprehend-out/topic-terms.csv\n",
    "\n",
    "comprehend_tars = tarfile.open('comprehend-out/output.tar.gz')\n",
    "comprehend_tars.extractall('./comprehend-out/')\n",
    "comprehend_tars.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}