{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a266ef",
   "metadata": {},
   "source": [
    "# Getting insight from customer reviews using Amazon Comprehend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ac667",
   "metadata": {},
   "source": [
    "## Comprehend Topic Modelling Job Notebook\n",
    "In the previous Notebook we performed data cleaning, exploration, and analysis. Now in this Notebook we will run a Topic Modeling job in Amazon Comprehend to get - \n",
    "\n",
    "\n",
    "1. List of words associated with each topic with high probability\n",
    "2. Assignment of each document to topics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde059b8",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "<a id=\"InitialiazeS3Data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f42e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json, time, tarfile, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client and session information\n",
    "session = boto3.Session()\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Account id. Required downstream.\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "# Initializing Comprehend client\n",
    "comprehend = boto3.client(service_name='comprehend', \n",
    "                          region_name=session.region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315cbe1d",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e17c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of topics set to 5 after having a human-in-the-loop\n",
    "# This needs to be fully aligned with topicMaps dictionary in the third script \n",
    "NUMBER_OF_TOPICS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd6e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file format of one review per line\n",
    "input_doc_format = \"ONE_DOC_PER_LINE\"\n",
    "\n",
    "# Role arn (Hard coded, masked)\n",
    "data_access_role_arn = \"arn:aws:iam::XXXXXXXXXXXX:role/service-role/AmazonSageMaker-ExecutionRole-XXXXXXXXXXXXXXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da53f5",
   "metadata": {},
   "source": [
    "### Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for S3 bucket and input data file\n",
    "BUCKET = 'clothing-shoe-jewel-tm-blog'\n",
    "input_s3_url = 's3://' + BUCKET + '/out/' + 'TransformedReviews.txt'\n",
    "output_s3_url = 's3://' + BUCKET + '/out/' + 'output/'\n",
    "\n",
    "# Final dataframe where we will join Comprehend outputs later\n",
    "S3_FEEDBACK_TOPICS = 's3://' + BUCKET + '/out/' + 'FinalDataframe.csv'\n",
    "\n",
    "# Local copy of Comprehend output\n",
    "LOCAL_COMPREHEND_OUTPUT_DIR = os.path.join('comprehend_out', '')\n",
    "LOCAL_COMPREHEND_OUTPUT_FILE = os.path.join(LOCAL_COMPREHEND_OUTPUT_DIR, 'output.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CONFIG={\n",
    "    # The S3 URI where Comprehend output is placed.\n",
    "    'S3Uri':    input_s3_url,\n",
    "    # Document format\n",
    "    'InputFormat': input_doc_format,\n",
    "}\n",
    "OUTPUT_CONFIG={\n",
    "    # The S3 URI where Comprehend output is placed.\n",
    "    'S3Uri':    output_s3_url,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08a3f0",
   "metadata": {},
   "source": [
    "### Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Comprehend input file just to double check if number of reviews \n",
    "# and the number of lines in the input file have an exact match.\n",
    "obj = s3.Object(input_s3_url)\n",
    "comprehend_input = obj.get()['Body'].read().decode('utf-8')\n",
    "comprehend_input_lines = len(comprehend_input.split('\\n'))\n",
    "\n",
    "# Reviews where Comprehend outputs will be merged\n",
    "df = pd.read_csv(S3_FEEDBACK_TOPICS)\n",
    "review_df_length = df.shape[0]\n",
    "\n",
    "# The two lengths must be equal\n",
    "assert comprehend_input_lines == review_df_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7e2f5",
   "metadata": {},
   "source": [
    "### Topic Modelling Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359af63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Comprehend topic modelling job.\n",
    "# Specifies the number of topics, input and output config and IAM role ARN \n",
    "# that grants Amazon Comprehend read access to data.\n",
    "start_topics_detection_job_result = comprehend.start_topics_detection_job(\n",
    "                                                    NumberOfTopics=NUMBER_OF_TOPICS,\n",
    "                                                    InputDataConfig=INPUT_CONFIG,\n",
    "                                                    OutputDataConfig=OUTPUT_CONFIG,\n",
    "                                                    DataAccessRoleArn=data_access_role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895fdb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start_topics_detection_job_result: ' + json.dumps(start_topics_detection_job_result))\n",
    "\n",
    "# Job ID is required downstream for extracting the Comprehend results\n",
    "job_id = start_topics_detection_job_result[\"JobId\"]\n",
    "print('job_id: ', job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84b88d0",
   "metadata": {},
   "source": [
    "### Check Topic Detection Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic detection takes a while to complete. \n",
    "# We can track the current status by calling Use the DescribeTopicDetectionJob operation.\n",
    "# Keeping track if Comprehend has finished its job\n",
    "description = comprehend.describe_topics_detection_job(JobId=job_id)\n",
    "\n",
    "topic_detection_job_status = description['TopicsDetectionJobProperties'][\"JobStatus\"]\n",
    "print(topic_detection_job_status)\n",
    "while topic_detection_job_status not in [\"COMPLETED\", \"FAILED\"]:\n",
    "    time.sleep(120)\n",
    "    topic_detection_job_status = comprehend.describe_topics_detection_job(JobId=job_id)['TopicsDetectionJobProperties'][\"JobStatus\"]\n",
    "    print(topic_detection_job_status)\n",
    "\n",
    "topic_detection_job_status = comprehend.describe_topics_detection_job(JobId=job_id)['TopicsDetectionJobProperties'][\"JobStatus\"]\n",
    "print(topic_detection_job_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428a6a2",
   "metadata": {},
   "source": [
    "### Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22bd92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket prefix where model artifacts are stored\n",
    "prefix = f'{account_id}-TOPICS-{job_id}'\n",
    "\n",
    "# Model artifact zipped file\n",
    "artifact_file = 'output.tar.gz'\n",
    "\n",
    "# Location on S3 where model artifacts are stored\n",
    "target = f's3://{BUCKET}/out/output/{prefix}/{artifact_file}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66783c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Comprehend output from S3 to local notebook instance\n",
    "! aws s3 cp {target}  ./comprehend-out/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the Comprehend output file. \n",
    "# Two files are now saved locally- \n",
    "#       (1) comprehend-out/doc-topics.csv and \n",
    "#       (2) comprehend-out/topic-terms.csv\n",
    "\n",
    "comprehend_tars = tarfile.open(LOCAL_COMPREHEND_OUTPUT_FILE)\n",
    "comprehend_tars.extractall(LOCAL_COMPREHEND_OUTPUT_DIR)\n",
    "comprehend_tars.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
